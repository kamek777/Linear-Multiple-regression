---
title: "Regresja logistyczna - projekt"
author:
  name: Kwiek Kamil
  affiliation:
subtitle: 
output:
  html_document:
    theme: darkly
    df_print: paged
    toc: true
    toc_float: true
---



# Projekt 3

W pliku `banknotes.csv` znajdują się dane opisujące obrazy banknotów. Dane powstały poprzez transformatę falową (wavelett transform) zastosowaną do obrazów w skali szarości rozmiaru 400x400 pikseli. Po zastosowaniu transformaty wyliczono cztery charakterystyki liczbowe obrazu - wariancję, skośność, kurtozę oraz entropię. 

Za pomocą modelu regresji logistycznej sprawdzimy czy za pomocą tej metody jesteśmy w stanie dobrze odróżnić banknoty prawdziwe od fałszywych. 

```{r, message = FALSE,echo=FALSE,warning=FALSE}
library(tidyverse)
library(caret)
library(ggfortify)
library(knitr)
library(kableExtra)
library(plotly)
```
```{r, message = FALSE}
bank <- readr::read_csv('C:/Users/PC/Downloads/banknote.csv', col_names = FALSE)
```

## Przedstawienie danych 

Dane zapisane są w następującej postaci:

- `X1` - wariancja,
- `X2` - skośność,
- `X3` - kurtoza,
- `X4` - entropia,
- `X5` - 1 prawdziwe, 0 fałszywe.


```{r}
bank %>% count(X5)
```

Widzimy, że zbiór danych `banknote` nie jest zbilansowany. Posiada więcej fałszywych banknotów niż prawdziwych.

## Normalność

Przy użyciu histogramów oraz testu Shapiro-Wilka sprawdzamy rozkłady naszych zmiennych.

```{r}
wykres <- plot_ly(alpha = 0.7)
wykres <- wykres %>% add_histogram(x = bank$X1, name = "X1")
wykres <- wykres %>% add_histogram(x = bank$X2, name = "X2")
wykres <- wykres %>% add_histogram(x = bank$X3, name = "X3")
wykres <- wykres %>% add_histogram(x = bank$X4, name = "X4")
wykres <- wykres %>% layout(barmode = "stack")

wykres
```
```{r}
shapiro.test(bank$X1)
shapiro.test(bank$X2)
shapiro.test(bank$X3)
shapiro.test(bank$X4)
```

Z testu Shapiro-Wilka $p-value < 0,05$, zatem odrzucamy $H_0$ i
stwierdzamy, że wariancja, skośność, kurtoza oraz entropia nie mają rozkładu normalnego.

## Model regresji logistycznej

```{r}
regresja_logistyczna <- glm(X5~X1+X2+X3+X4,data=bank,family = "binomial")
summary(regresja_logistyczna)
```


* `Estimate`: szacunki przechwycenia $(\beta_0)$ i współczynnika beta związanego z każdą zmienną przewidującą
* `Std.Error`: błąd standardowy oszacowań współczynników. Przedstawia on dokładność współczynników. Im większy błąd standardowy, tym mniejsza pewność co do oszacowania.
* `wartość z`: statystyka Z, która jest estymacją współczynnika (kolumna 2) podzieloną przez błąd standardowy estymacji (kolumna 3)
* `Pr(>|z|)`: Wartość p odpowiadająca statystyce z. Im mniejsza wartość p, tym bardziej znaczący jest szacunek.

Różnica pomiędzy odchyleniem zerowym a odchyleniem resztowym mówi nam, że model jest dobrze dopasowany. Większa różnica jest lepsza dla modelu. `Null deviance` to wartość, gdy w równaniu mamy tylko przechwyt bez żadnych zmiennych, a `Residual deviance` to wartość, gdy bierzemy pod uwagę wszystkie zmienne. Ma to sens, aby uznać model za dobry, jeśli ta różnica jest wystarczająco duża.

W naszym przypadku wartość funkcji logitowej $ln\bigg(\frac{p}{1-p}\bigg)$ z autentyczności banknotów dla wariancji, skośności, kurtozy oraz entropii, wynosi $7,3218$.

- Różnica funkcji logitowej autentyczności pomiędzy wartością wariancji wynosi $-7,8593$, otrzymaliśmy $p-value < 0,05$, więc odrzucamy $H_0$. Nie istnieją żadne różnice pomiędzy autentycznością, a wariancją.  
- Różnica funkcji logitowej autentyczności pomiędzy wartością skośności wynosi $-4,1910$, otrzymaliśmy $p-value < 0,05$, więc odrzucamy $H_0$. Nie istnieją żadne różnice pomiędzy autentycznością, a skośnością.
- Różnica funkcji logitowej autentyczności pomiędzy wartością kurtozy wynosi $-5,2874$, otrzymaliśmy $p-value < 0,05$, więc odrzucamy $H_0$. Nie istnieją żadne różnice pomiędzy autentycznością, a kurtozą.
- Różnica funkcji logitowej autentyczności pomiędzy wartością entropii wynosi $-0,6053$, otrzymaliśmy $p-value > 0,05$, więc nie mamy podstaw do odrzucenia $H_0$, zatem istnieją różnice pomiędzy autentyycznością banknotu, a jego entropią. Co oznacza, że wpływa ona na autentyczność banknotu.



```{r}
dec_bond <- regresja_logistyczna$coefficients
logistic2_slope = -dec_bond[2]/dec_bond[3]
logistic2_intercept = -dec_bond[1]/dec_bond[3]
```


```{r}
ggplot(bank, aes(x = X1, y = X2, color = as.factor(X5))) + 
  geom_point() + 
  geom_abline(slope = logistic2_slope, intercept = logistic2_intercept, color = 'blue', linetype = 'dashed') + 
    labs(color = 'X5')
```


```{r}
ggplot(bank, aes(x = X1, y = X3, color = as.factor(X5))) + 
  geom_point() + 
  geom_abline(slope = logistic2_slope, intercept = logistic2_intercept, color = 'blue', linetype = 'dashed') + 
    labs(color = 'X5')
```


```{r}
ggplot(bank, aes(x = X1, y = X4, color = as.factor(X5))) + 
  geom_point() + 
  geom_abline(slope = logistic2_slope, intercept = logistic2_intercept, color = 'blue', linetype = 'dashed') + 
    labs(color = 'X5')
```

Wykresy przedstawiają hiperpłaszyznę decyzyjną naszego modelu.


## Walidacja jakości modelu 
```{r}
logit_prediction <- predict(regresja_logistyczna, bank[c(1:4)], type = 'response')
head(logit_prediction)
```
```{r}
logistic2_predictions <- ifelse(logit_prediction > 0.5, 1, 0)
head(logistic2_predictions)
```

```{r}
library(caret)
caret::confusionMatrix(data = as.factor(logistic2_predictions), reference = as.factor(bank$X5))
```

```{r}
table <- data.frame(confusionMatrix(as.factor(logistic2_predictions), as.factor(bank$X5))$table)

plotTable <- table %>%
  mutate(goodbad = ifelse(table$Prediction == table$Reference, "good", "bad")) %>%
  group_by(Reference) %>%
  mutate(prop = Freq/sum(Freq))

ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(good = "green", bad = "red")) +
  theme_bw() +
  labs(title = "Macierz modelu regresja_logistyczna") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlim(rev(levels(table$Reference)))
```


Przy pomocy biblioteki `caret` stworzyliśmy macierz pomyłek. Jej charakterystyki liczbowe przedstawiają się w następujący sposób:

- **True-Negative** - fałszywe próbki, które zostały sklasyfikowane jako fałszywe (757),
- **True-Positive** - prawdziwe próbki, które zostały sklasyfikowane jako prawdziwe (604),
- **False-Negative** - prawdziwe próbki, które zostały sklasyfikowane jako fałszywe (5),
- **False-Positive** - fałszywe próbki, które zostały sklasyfikowane jako prawdziwe (6).


Dokładność to liczba próbek poprawnie sklasyfikowanych spośród wszystkich próbek obecnych w zbiorze testowym:

$Accuracy = \frac{TP+TN}{TP+FP+TN+FN}$, u nas wynosi $0,992$.

$NIR > 0,5$, zatem nasz model nie jest gorszy od rzutu monetą.

Współczynnik Kappa może być użyty do oceny dokładności klasyfikacji. Przyjmuje wartości $[-1,1]$ wartość większa niż 0 wskazuje, że klasyfikacja jest znacznie lepsza niż losowa.


Czułość to liczba próbek rzeczywiście należących do klasy pozytywnej spośród wszystkich próbek, które zostały przewidziane przez model jako należące do klasy pozytywnej.

$Sensitivity = \frac{TP}{TP+FN}$.

Swoistość to liczba próbek przewidywanych prawidłowo jako należące do klasy negatywnej spośród wszystkich próbek w zbiorze danych, które rzeczywiście należą do klasy negatywnej.

$Sensitivity = \frac{TN}{TN+FP}$.

## Zbiór treningowy i testowy

```{r}
library(caret)
train_test_split <- createDataPartition(bank$X5, list = FALSE, p=0.75)
bank_train <- bank[train_test_split,]
bank_test <- bank[-train_test_split,]
cat(dim(bank_train),dim(bank_test))
```

```{r}
table(bank$X5)
```
Wszystkie banknoty prawdziwe i fałszywe dostępne.

```{r}
table(bank_train$X5)
```
Banknoty treningowe, tylko $\frac{3}{4}$ banknotów. (p=0.75)

```{r}
table(bank_test$X5)
```
Te banknoty, które odjeliśmy od wszystkich banknotów by otrzymać banknoty treningowe.

```{r}
kable(summary(bank_train), escape = F) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

```{r}
bank_train_model <- glm(X5 ~ X1+X2+X3+X4 , data = bank_train, family='binomial')
summary(bank_train_model)
```
```{r}
logit_prediction_bank_train_model <- predict(bank_train_model, bank_test, type = 'response')
head(logit_prediction_bank_train_model)
```
```{r}
logistic2_predictions_bank_train_model <- ifelse(logit_prediction_bank_train_model > 0.5, 1, 0)
head(logistic2_predictions_bank_train_model)
```

```{r}
library(caret)
caret::confusionMatrix(data = as.factor(logistic2_predictions_bank_train_model), reference = as.factor(bank_test$X5))
```
```{r}
table <- data.frame(confusionMatrix(as.factor(logistic2_predictions_bank_train_model), as.factor(bank_test$X5))$table)

plotTable <- table %>%
  mutate(goodbad = ifelse(table$Prediction == table$Reference, "good", "bad")) %>%
  group_by(Reference) %>%
  mutate(prop = Freq/sum(Freq))

ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
  scale_fill_manual(values = c(good = "green", bad = "red")) +
  theme_bw() +
  labs(title = "Macierz modelu bank_train") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlim(rev(levels(table$Reference)))
```


```{r}
fmpreds <- predict(bank_train_model, bank_test, type = 'response')
fmpreds_classes <- ifelse(fmpreds > 0.5, 1, 0)
baseline_cm <- confusionMatrix(factor(fmpreds_classes), factor(bank_test$X5))
baseline_cm
```

## Krzywa ROC

Analiza krzywej charakterystyki operacyjnej odbiornika (ROC — Receiver operating characteristic) jest użytecznym narzędziem oceny dokładności predykcji modelu poprzez wykreślenie czułości wobec (1-swoistości) testu klasyfikacyjnego (przy progu zmieniającym się w całym zakresie wyników testu diagnostycznego).

```{r, message=FALSE}
roc_rl <- pROC::roc(response = bank_test$X5, predictor = fmpreds)
```
```{r}
pROC::ggroc(roc_rl, legacy.axes = TRUE) + geom_abline(slope = 1, intercept = 0) +
  labs(title = "Krzywa ROC bank_train")+
  theme(plot.title = element_text(hjust = 0.5))
```

```{r}
roc_rl$auc
```

Krzywa kształtem bardzo przypomina trójkąc co oznacza, że nasz model jest prawie "idealny", a pole pod wykresem wynosi $0,9997$.

## Podsumowanie
Dzięki tej metodzie jesteśmy w stanie odróżnić prawdziwe banknoty od fałszywych, ale zdarza się, że nasz model popełni błąd. Tworząc model treningowy z $\frac{3}{4}$ wszystkich banknotów uzyskaliśmy lepsze współczynniki `No Information Rate`,  `Sensitivity` oraz `Specificity`. Co za tym idzie nasz model jest bliższy modelowi o idealnych parametrach.  




